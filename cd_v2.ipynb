{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nirb28/ee-predict/blob/main/cd_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def resolve_path_gdrive(relativePath):\n",
        "    if os.path.exists('/content/drive'):\n",
        "        return '/content/drive/MyDrive/work/gdrive-workspaces/git/ee-predict/' + relativePath\n",
        "    else:\n",
        "        return relativePath\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=False)"
      ],
      "metadata": {
        "id": "sqVMg9hstUzl",
        "is_executing": true
      },
      "id": "sqVMg9hstUzl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "initial_id",
      "metadata": {
        "collapsed": true,
        "id": "initial_id",
        "ExecuteTime": {
          "end_time": "2024-05-27T19:35:14.730964600Z",
          "start_time": "2024-05-27T19:35:14.716958100Z"
        }
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "import pandas as pd\n",
        "import numpy as np, os, csv\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "MODEL_REFRESH_STRATEGY = \"RETRAIN\" # Retrain model after every loop: RETRAIN, PRETRAIN\n",
        "OPTIMIZE_STRATEGY = \"NEWLY_ADDED\" # Only optimize the newly added catalyst: NEWLY_ADDED, ALL\n",
        "MODEL_FIT_USE_COLS = \"models/high_corr_cols.txt\" # Use all the columns: \"ALL\", \"models/high_corr_cols.txt\"\n",
        "DEFAULT_PCA_DIMENSION = 4\n",
        "START_SAMPLE_SIZE = 3\n",
        "DATAFILE_NAME = \"merged_large_catalyst.csv\" # \"reduced_dim_space_ddG.csv\", \"merged_large_catalyst.csv\"\n",
        "CD_STEP_SIZE = 0.001\n",
        "CD_ITERATIONS_PER_STEP = 2\n",
        "CD_ITERATIONS = 10\n",
        "\n",
        "df = pd.read_csv(resolve_path_gdrive('data/' + DATAFILE_NAME))\n",
        "## removing ddG = 0 and indexing catalysts\n",
        "df = df[df['ddG'] != 0]\n",
        "df.set_index('Catalyst', inplace=True)\n",
        "\n",
        "if DATAFILE_NAME == \"reduced_dim_space_ddG.csv\":\n",
        "  X_COLS = ['x', 'y', 'z']\n",
        "else:\n",
        "  if MODEL_FIT_USE_COLS == \"ALL\":\n",
        "    X_COLS = df.columns[~df.columns.isin(['Catalyst', 'ddG'])]\n",
        "  else:\n",
        "    with open(resolve_path_gdrive(MODEL_FIT_USE_COLS)) as f:\n",
        "      reader = csv.reader(f)\n",
        "      X_COLS = list(reader)[0][:-1]"
      ],
      "metadata": {
        "id": "840f26aaf0a91b45",
        "ExecuteTime": {
          "end_time": "2024-05-27T19:35:17.465071600Z",
          "start_time": "2024-05-27T19:35:16.164993900Z"
        }
      },
      "id": "840f26aaf0a91b45"
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "yv-c1kJuE75p"
      },
      "id": "yv-c1kJuE75p",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# method to make a regression model from the provided catalysts\n",
        "from sklearn.cross_decomposition import PLSRegression\n",
        "def make_pls_model(df_catalysts, PCA_DIMENSION=DEFAULT_PCA_DIMENSION):\n",
        "    X = df_catalysts[X_COLS]\n",
        "    y = df_catalysts['ddG']\n",
        "    model = PLSRegression(n_components=PCA_DIMENSION)\n",
        "    print(\"PLS: Fitting model with {} rows and {} columns. PCA dimensions are {}\"\n",
        "        .format(len(X), len(X.columns), PCA_DIMENSION))\n",
        "    # fitting the model\n",
        "    return model.fit(X, y)\n",
        "\n",
        "## Importing model created in \"eda.ipynb\"\n",
        "from joblib import dump, load\n",
        "def load_model(path):\n",
        "  return load(path)\n",
        "\n",
        "pls_large_saved_model = load_model(resolve_path_gdrive('models/pls_large.joblib'))\n",
        "print(pls_large_saved_model)\n",
        "## Read the dimension directly from the model so that if the model changes\n",
        "## the dimension will be reflected automatically\n",
        "PCA_DIMENSION = pls_large_saved_model.n_components\n",
        "\n",
        "def pls_predict_ee(pls_model, properties):\n",
        "    return pls_model.predict(properties.reshape(1,-1))\n",
        "\n",
        "## Add a predicted ddG column to the df\n",
        "#df['pred_ddG'] = df.apply(lambda x: pls_predict_ee(pls_large_saved_model, np.array(x[X_COLS]))[0][0], axis=1)"
      ],
      "metadata": {
        "ExecuteTime": {
          "start_time": "2024-05-27T19:35:19.365464500Z"
        },
        "id": "164770e72ca8a958"
      },
      "id": "164770e72ca8a958"
    },
    {
      "cell_type": "code",
      "source": [
        "# start with a few randomly selected catalyst\n",
        "random_catalyst_df = df.sample(START_SAMPLE_SIZE)\n",
        "## This will be used to track progress of coordinate descent\n",
        "print(\"The max value (target) of the ddG is at {}. Currently we have reached {}.\".format(df['ddG'].max(), random_catalyst_df['ddG'].max()))\n",
        "random_catalyst_df"
      ],
      "metadata": {
        "id": "_hwUnCcWv9dF",
        "ExecuteTime": {
          "end_time": "2024-05-27T19:35:18.227250800Z",
          "start_time": "2024-05-27T19:35:18.197305600Z"
        }
      },
      "id": "_hwUnCcWv9dF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "original_ee = df['ddG']\n",
        "# Function to optimize catalyst properties using coordinate descent\n",
        "def optimize_catalysts(catalysts, pls_model=None, iterations=CD_ITERATIONS,\n",
        "                       cd_iterations=CD_ITERATIONS_PER_STEP, step_size=CD_STEP_SIZE):\n",
        "    if pls_model == None:\n",
        "        pls_model = make_pls_model(random_catalyst_df)\n",
        "    optimized_catalysts = np.copy(catalysts)\n",
        "    for _ in range(iterations):\n",
        "        for i in range(len(optimized_catalysts)):\n",
        "            ## we have few options for the original_ee. We can use from the dataset or get the prediction\n",
        "            ## from the model. The prediction makes sense as we want to traverse in the direction where\n",
        "            ## ee improves according to the model\n",
        "\n",
        "            ## when using ddG from dataset\n",
        "            #original_ee = df.iloc[df.index.get_loc(catalysts[i:i+1].index[0])]['ddG']\n",
        "            ## when using the model\n",
        "            original_ee = pls_predict_ee(pls_model, optimized_catalysts[i])\n",
        "            for x in range(len(optimized_catalysts[i])):\n",
        "                for cd in range(cd_iterations):\n",
        "                    old_value = optimized_catalysts[i, x]\n",
        "                    optimized_catalysts[i, x] = old_value + step_size\n",
        "                    new_ee = pls_predict_ee(pls_model, optimized_catalysts[i])\n",
        "                    if new_ee < original_ee:\n",
        "                        optimized_catalysts[i, x] = old_value - step_size\n",
        "                        new_ee = pls_predict_ee(pls_model, optimized_catalysts[i])\n",
        "                    if new_ee < original_ee:\n",
        "                        optimized_catalysts[i, x] = old_value\n",
        "                        break\n",
        "                    #print('Found a direction for higher ddG')\n",
        "    return optimized_catalysts\n"
      ],
      "metadata": {
        "id": "3ccce164af24176d",
        "ExecuteTime": {
          "end_time": "2024-05-27T19:35:28.984868700Z",
          "start_time": "2024-05-27T19:35:23.244966Z"
        }
      },
      "id": "3ccce164af24176d"
    },
    {
      "cell_type": "code",
      "source": [
        "if MODEL_REFRESH_STRATEGY == \"RETRAIN\":\n",
        "  new_optimized_catalysts = optimize_catalysts(random_catalyst_df[X_COLS])\n",
        "else:\n",
        "  new_optimized_catalysts = optimize_catalysts(random_catalyst_df[X_COLS], pls_large_saved_model)"
      ],
      "metadata": {
        "id": "E4cxDZVnoTqM"
      },
      "id": "E4cxDZVnoTqM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Perform k-nearest neighbors analysis\n",
        "def recomputeKNN(df, removePointsDF = None):\n",
        "  if len(removePointsDF) > 0:\n",
        "    df.drop(removePointsDF.index, axis=0, inplace=True)\n",
        "  num_neighbors = 1  # Number of neighbors to consider\n",
        "  knn = NearestNeighbors(n_neighbors=num_neighbors)\n",
        "  print('KNN: Fitting model with {} points.'.format(len(df)))\n",
        "  knn.fit(df)  # Using all the catalysts\n",
        "  return knn\n",
        "\n",
        "knn = recomputeKNN(df[X_COLS], random_catalyst_df)"
      ],
      "metadata": {
        "id": "5148feb1e89070b9",
        "ExecuteTime": {
          "end_time": "2024-05-27T19:35:34.744354400Z",
          "start_time": "2024-05-27T19:35:34.704753900Z"
        }
      },
      "id": "5148feb1e89070b9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "## Recursive Loop\n",
        "## The method will get unique neighbors that are not already in the list.\n",
        "## If the 1st neighbor is already in the list then we try the 2nd, 3rd and so on\n",
        "## till a unique neighbor is found\n",
        "def find_unique_neighbors_add(knn, point, addToDf, neighbor_number=1):\n",
        "    distances, indices = knn.kneighbors([point], neighbor_number)\n",
        "    neighbor_catalyst = df.iloc[[indices[0][neighbor_number-1]]]\n",
        "    if neighbor_catalyst.index[0] in addToDf.index:\n",
        "        #get next neighbor\n",
        "        neighbor_catalyst = find_unique_neighbors_add(knn, point, addToDf, neighbor_number+1)\n",
        "    return neighbor_catalyst\n",
        "\n",
        "def process_neighbors(knn, for_points, addToDf):\n",
        "    for i in range(len(for_points)):\n",
        "        neighbor_catalyst = find_unique_neighbors_add(knn, for_points[i], addToDf)\n",
        "        ## Add found catalysts into our batch (random_catalyst_df)\n",
        "        if len(neighbor_catalyst) > 0:\n",
        "            addToDf = pd.concat([addToDf, neighbor_catalyst], ignore_index=False, sort=True)\n",
        "    return addToDf\n",
        "\n",
        "random_catalyst_df = process_neighbors(knn, new_optimized_catalysts, random_catalyst_df)\n",
        "random_catalyst_df[X_COLS]"
      ],
      "metadata": {
        "id": "10bebdf2fff05fa4",
        "ExecuteTime": {
          "end_time": "2024-05-27T19:50:24.719248900Z",
          "start_time": "2024-05-27T19:50:21.794201100Z"
        }
      },
      "id": "10bebdf2fff05fa4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# We will now do all this in a single loop\n",
        "\n",
        "## Maximum of entire dataset\n",
        "max_ddG = df['ddG'].max()\n",
        "print(\"The max value (target) of the ddG is {}. Model training strategy is {}\".format(max_ddG, MODEL_REFRESH_STRATEGY))\n",
        "\n",
        "## Get random rows\n",
        "#random_catalyst_df = df.loc[not_highest_index].sample(START_SAMPLE_SIZE)\n",
        "## Get lowest ddG to start\n",
        "#random_catalyst_df = df.sort_values('ddG').head(START_SAMPLE_SIZE)\n",
        "## Static list to start\n",
        "random_catalyst_df = df[df['ddG'] > .5].sort_values('ddG').head(START_SAMPLE_SIZE)\n",
        "\n",
        "while(len(random_catalyst_df) < len(df)):\n",
        "    print(\"The current maximum ddg is at: \" + str(random_catalyst_df['ddG'].max()))\n",
        "    what_to_optimize = random_catalyst_df[X_COLS]\n",
        "    if OPTIMIZE_STRATEGY == \"NEWLY_ADDED\":\n",
        "        what_to_optimize = what_to_optimize.tail(START_SAMPLE_SIZE)\n",
        "    new_optimized_catalysts = optimize_catalysts(what_to_optimize,\n",
        "        pls_large_saved_model if MODEL_REFRESH_STRATEGY == \"PRETRAIN\" else None)\n",
        "    random_catalyst_df = process_neighbors(knn, new_optimized_catalysts, random_catalyst_df)\n",
        "    # recompute knn so that we dont find the same neighbors in the next loop around\n",
        "    knn = recomputeKNN(df[X_COLS], random_catalyst_df)\n",
        "    if random_catalyst_df['ddG'].max() >= max_ddG:\n",
        "        print(\"Found the highest ddG {}. Exiting.\".format(str(random_catalyst_df['ddG'].max())))\n",
        "        break"
      ],
      "metadata": {
        "id": "67bcc19eae370159",
        "is_executing": true,
        "ExecuteTime": {
          "start_time": "2024-05-27T20:13:33.645466400Z"
        }
      },
      "id": "67bcc19eae370159"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# sample prediction with model\n",
        "properties1 = (np.array([ 0.75813041,  0.67727654,  0.68692902,  0.57403813, -0.39901283,\n",
        "       -0.83317389, -0.69366434, -0.76423736, -0.18775295, -0.89697628,\n",
        "       -0.93897206, -0.64303136, -0.50508299, -0.82567658, -0.29773217,\n",
        "       -0.23605932, -0.26722481,  0.02879822, -0.69189841]))\n",
        "#pls_predict_ee(pls_large_saved_model, properties1)\n",
        "# random_catalyst_df = random_catalyst_df[~random_catalyst_df.index.duplicated(keep='first')]"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-05-27T19:35:44.886986300Z",
          "start_time": "2024-05-27T19:35:44.870652400Z"
        },
        "id": "d0a69f10c8d70c9a"
      },
      "id": "d0a69f10c8d70c9a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# prompt: get last 3 rows of random_catalyst_df[X_COLS]\n",
        "random_catalyst_df[X_COLS].tail(3)\n"
      ],
      "metadata": {
        "id": "76087d0c889f129a"
      },
      "id": "76087d0c889f129a"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nSXY4XSPDKPA"
      },
      "id": "nSXY4XSPDKPA",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}